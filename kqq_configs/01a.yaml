---
sample_rate: 44100
clip_duration: 2.
target_stem: "vocals"

train_datasets:
    MUSDB18HQ:
        root: "/datasets/musdb18hq"
        split: "train"

test_datasets:
    MUSDB18HQ:
        root: "/datasets/musdb18hq"
        split: "test"
        
model:
    name: UNet
    n_fft: 2048 
    hop_length: 441

    # trainable: True
    # block_size: 2048  # Maximize block size
    # audio_latent_dim:  # Leave blank. Parsed later from audio_encoder
    # vocab_size:  # Leave blank. Parsed later from len(tokenier)
    # n_layer: 12
    # n_head: 12
    # n_embd: 768
    
train:
    device: "cuda"
    num_workers: 16
    loss: l1
    optimizer: AdamW
    lr: 1e-3
    warm_up_steps: 1000  # Leave blank if no warm up is used
    batch_size_per_device: 4
    test_every_n_steps: 10000
    save_every_n_steps: 20000
    training_steps: 200000
    resume_ckpt_path:  # Leave blank if train from scratch